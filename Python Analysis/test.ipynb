{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting batch process......\n",
      "loading transaction data......\n",
      "transaction data loaded\n",
      "        InvoiceNumber InvoiceDate CustomerCode  ProductCode  BaseQty  \\\n",
      "0         HSX61C00685  2022-02-01    OWK001831     10000566      6.0   \n",
      "1         HSA22C00334  2022-02-01    RKP003445     10000512    230.0   \n",
      "2         HSR25C00344  2022-02-01    PKA008980     10000548      5.0   \n",
      "3         HSR67C00536  2022-02-01    JTG004975     10000571     24.0   \n",
      "4         HSM61C00018  2022-02-01    PSM000068     10000604     40.0   \n",
      "...               ...         ...          ...          ...      ...   \n",
      "7230273   HSAI1C02522  2022-08-04    SPM001751     10000600     50.0   \n",
      "7230274   HSA25C03600  2022-08-04    RKP005221     10000600     50.0   \n",
      "7230275   HSW05C03323  2022-08-04    YSR001143     10000600     50.0   \n",
      "7230276   HSYY3C02062  2022-08-04    BVD001250     10000600     50.0   \n",
      "7230277   HSAP5C01879  2022-08-04    NSV008958     10000600     50.0   \n",
      "\n",
      "         NetAmount  DiscAmount  UnitPrice  \\\n",
      "0            46.73         1.0       8.50   \n",
      "1          2219.63        40.0      10.50   \n",
      "2            48.60         0.0      10.40   \n",
      "3           272.90         4.0      12.33   \n",
      "4           500.00         5.0      13.50   \n",
      "...            ...         ...        ...   \n",
      "7230273     485.98         5.0      10.50   \n",
      "7230274     485.98         5.0      10.50   \n",
      "7230275     485.98         5.0      10.50   \n",
      "7230276     485.98         5.0      10.50   \n",
      "7230277     485.98         5.0      10.50   \n",
      "\n",
      "                                 ProductNameTH GroupNameLevel1 GroupNameLevel2  \n",
      "0               เอ็มเกลือแร่ 250มล เหลือง 1x24   M-ELECTROLYTE     SPORT DRINK  \n",
      "1                    ลิโพวิตัน-ดี 100มล 1X5X10            LIPO    ENERGY DRINK  \n",
      "2                       ลิโพ-ไฟน์ 100มล 1X5X10            LIPO    ENERGY DRINK  \n",
      "3          คาลพิส โซดา ยูสุ ฮันนี่ 245มล 1X4X6    CALPIS LACTO     REFRESHMENT  \n",
      "4                 ซี-วิท ทับทิม 140 มล. 1x3x10          C-VITT     REFRESHMENT  \n",
      "...                                        ...             ...             ...  \n",
      "7230273  เอ็ม-150 ไฮ วิตามินบี12 150มล. 1x5x10           M-150    ENERGY DRINK  \n",
      "7230274  เอ็ม-150 ไฮ วิตามินบี12 150มล. 1x5x10           M-150    ENERGY DRINK  \n",
      "7230275  เอ็ม-150 ไฮ วิตามินบี12 150มล. 1x5x10           M-150    ENERGY DRINK  \n",
      "7230276  เอ็ม-150 ไฮ วิตามินบี12 150มล. 1x5x10           M-150    ENERGY DRINK  \n",
      "7230277  เอ็ม-150 ไฮ วิตามินบี12 150มล. 1x5x10           M-150    ENERGY DRINK  \n",
      "\n",
      "[7230278 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"starting batch process......\")\n",
    "\n",
    "print(\"loading transaction data......\")\n",
    "transaction_file_name = \"../ETL/CSV/obd_transaction.csv\"\n",
    "df = pd.read_csv(transaction_file_name, index_col=0)\n",
    "print(\"transaction data loaded\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming transaction data......\n",
      "ProductCode    10000183  10000186  10000187  10000204  10000205  10000213  \\\n",
      "InvoiceNumber                                                               \n",
      "HS792201004       False     False     False     False     False     False   \n",
      "HS792201005       False     False     False     False     False     False   \n",
      "HS792201006       False     False     False     False     False     False   \n",
      "HS792201007       False     False     False     False     False     False   \n",
      "HS792201008       False     False     False     False     False     False   \n",
      "...                 ...       ...       ...       ...       ...       ...   \n",
      "IVZZ62200297      False     False     False     False     False     False   \n",
      "IVZZ62200298      False     False     False     False     False     False   \n",
      "IVZZ62200299      False     False     False     False     False     False   \n",
      "IVZZ62200300      False     False     False     False     False     False   \n",
      "IVZZ62200301      False     False     False     False     False     False   \n",
      "\n",
      "ProductCode    10000235  10000245  10000250  10000280  ...  10000718  \\\n",
      "InvoiceNumber                                          ...             \n",
      "HS792201004       False     False     False     False  ...     False   \n",
      "HS792201005       False     False     False     False  ...     False   \n",
      "HS792201006       False     False     False     False  ...     False   \n",
      "HS792201007       False     False     False     False  ...     False   \n",
      "HS792201008       False     False     False     False  ...     False   \n",
      "...                 ...       ...       ...       ...  ...       ...   \n",
      "IVZZ62200297      False     False     False     False  ...     False   \n",
      "IVZZ62200298      False     False     False     False  ...     False   \n",
      "IVZZ62200299      False     False     False     False  ...     False   \n",
      "IVZZ62200300      False     False     False     False  ...     False   \n",
      "IVZZ62200301      False     False     False     False  ...     False   \n",
      "\n",
      "ProductCode    10000719  20000002  20000451  20000480  20000489  20000685  \\\n",
      "InvoiceNumber                                                               \n",
      "HS792201004       False     False     False     False     False     False   \n",
      "HS792201005       False     False     False     False     False     False   \n",
      "HS792201006       False     False     False     False     False     False   \n",
      "HS792201007       False     False     False     False     False     False   \n",
      "HS792201008       False     False     False     False     False     False   \n",
      "...                 ...       ...       ...       ...       ...       ...   \n",
      "IVZZ62200297      False     False     False     False     False     False   \n",
      "IVZZ62200298      False     False     False     False     False     False   \n",
      "IVZZ62200299      False     False     False     False     False     False   \n",
      "IVZZ62200300      False     False     False     False     False     False   \n",
      "IVZZ62200301      False     False     False     False     False     False   \n",
      "\n",
      "ProductCode    20001338  20001726  20001730  \n",
      "InvoiceNumber                                \n",
      "HS792201004       False     False     False  \n",
      "HS792201005       False     False     False  \n",
      "HS792201006       False     False     False  \n",
      "HS792201007       False     False     False  \n",
      "HS792201008       False     False     False  \n",
      "...                 ...       ...       ...  \n",
      "IVZZ62200297      False     False     False  \n",
      "IVZZ62200298      False     False     False  \n",
      "IVZZ62200299      False     False     False  \n",
      "IVZZ62200300      False     False     False  \n",
      "IVZZ62200301      False     False     False  \n",
      "\n",
      "[1641120 rows x 128 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# transform transaction table\n",
    "print(\"transforming transaction data......\")\n",
    "basket_df = df.groupby(['InvoiceNumber', 'ProductCode']).size().unstack(fill_value=0).astype(bool)\n",
    "print(basket_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating frequent itemsets with minimum support of 5%....\n",
      "     support                                  itemsets  length\n",
      "0   0.082677                                (10000302)       1\n",
      "1   0.075531                                (10000347)       1\n",
      "2   0.055541                                (10000359)       1\n",
      "3   0.128298                                (10000378)       1\n",
      "4   0.157608                                (10000430)       1\n",
      "..       ...                                       ...     ...\n",
      "84  0.051753            (10000640, 10000629, 10000600)       3\n",
      "85  0.083354            (10000602, 10000603, 10000604)       3\n",
      "86  0.086368            (10000627, 10000628, 10000629)       3\n",
      "87  0.059957            (10000640, 10000627, 10000628)       3\n",
      "88  0.065882  (10000600, 10000627, 10000628, 10000629)       4\n",
      "\n",
      "[89 rows x 3 columns]\n",
      "creating association rules [support, confidence, lift,  leverage, conviction] with minimum lift of 1 .......\n",
      "              antecedents           consequents  antecedent support  \\\n",
      "182            (10000603)  (10000602, 10000604)            0.209108   \n",
      "179  (10000602, 10000604)            (10000603)            0.098043   \n",
      "178  (10000602, 10000603)            (10000604)            0.135761   \n",
      "183            (10000604)  (10000602, 10000603)            0.152707   \n",
      "184  (10000627, 10000628)            (10000629)            0.142926   \n",
      "..                    ...                   ...                 ...   \n",
      "104            (10000504)  (10000640, 10000600)            0.368615   \n",
      "21             (10000628)            (10000504)            0.216609   \n",
      "20             (10000504)            (10000628)            0.368615   \n",
      "72   (10000512, 10000504)            (10000600)            0.096312   \n",
      "75             (10000600)  (10000512, 10000504)            0.677919   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \n",
      "182            0.098043  0.083354    0.398616  4.065739  0.062852    1.499804  \n",
      "179            0.209108  0.083354    0.850180  4.065739  0.062852    5.278954  \n",
      "178            0.152707  0.083354    0.613977  4.020611  0.062622    2.194926  \n",
      "183            0.135761  0.083354    0.545842  4.020611  0.062622    1.902948  \n",
      "184            0.152607  0.086368    0.604283  3.959723  0.064556    2.141410  \n",
      "..                  ...       ...         ...       ...       ...         ...  \n",
      "104            0.191135  0.072221    0.195927  1.025070  0.001766    1.005959  \n",
      "21             0.368615  0.081173    0.374745  1.016630  0.001328    1.009804  \n",
      "20             0.216609  0.081173    0.220212  1.016630  0.001328    1.004619  \n",
      "72             0.677919  0.065320    0.678215  1.000436  0.000028    1.000919  \n",
      "75             0.096312  0.065320    0.096354  1.000436  0.000028    1.000046  \n",
      "\n",
      "[210 rows x 9 columns]\n",
      "further cleaning of association rules [confidence >= 0.5, lift >= 1.5]....\n",
      "                        antecedents           consequents  antecedent support  \\\n",
      "179            (10000602, 10000604)            (10000603)            0.098043   \n",
      "178            (10000602, 10000603)            (10000604)            0.135761   \n",
      "183                      (10000604)  (10000602, 10000603)            0.152707   \n",
      "184            (10000627, 10000628)            (10000629)            0.142926   \n",
      "189                      (10000629)  (10000627, 10000628)            0.152607   \n",
      "180            (10000603, 10000604)            (10000602)            0.108376   \n",
      "202            (10000600, 10000629)  (10000627, 10000628)            0.117806   \n",
      "196  (10000600, 10000627, 10000628)            (10000629)            0.110560   \n",
      "185            (10000627, 10000629)            (10000628)            0.103019   \n",
      "197  (10000600, 10000627, 10000629)            (10000628)            0.078765   \n",
      "204            (10000627, 10000629)  (10000600, 10000628)            0.103019   \n",
      "52                       (10000603)            (10000604)            0.209108   \n",
      "53                       (10000604)            (10000603)            0.152707   \n",
      "198  (10000600, 10000628, 10000629)            (10000627)            0.077574   \n",
      "107            (10000512, 10000603)            (10000602)            0.087755   \n",
      "186            (10000628, 10000629)            (10000627)            0.102183   \n",
      "49                       (10000603)            (10000602)            0.209108   \n",
      "48                       (10000602)            (10000603)            0.196457   \n",
      "130            (10000600, 10000602)            (10000603)            0.105485   \n",
      "139            (10000600, 10000604)            (10000603)            0.085688   \n",
      "138            (10000600, 10000603)            (10000604)            0.117375   \n",
      "51                       (10000604)            (10000602)            0.152707   \n",
      "106            (10000512, 10000602)            (10000603)            0.084755   \n",
      "205            (10000628, 10000629)  (10000600, 10000627)            0.102183   \n",
      "131            (10000600, 10000603)            (10000602)            0.117375   \n",
      "135            (10000600, 10000604)            (10000602)            0.085688   \n",
      "61                       (10000629)            (10000628)            0.152607   \n",
      "161            (10000600, 10000629)            (10000628)            0.117806   \n",
      "165                      (10000629)  (10000600, 10000628)            0.152607   \n",
      "190            (10000640, 10000627)            (10000628)            0.098886   \n",
      "57                       (10000629)            (10000627)            0.152607   \n",
      "149            (10000600, 10000629)            (10000627)            0.117806   \n",
      "55                       (10000628)            (10000627)            0.216609   \n",
      "54                       (10000627)            (10000628)            0.252869   \n",
      "191            (10000640, 10000628)            (10000627)            0.091369   \n",
      "153                      (10000629)  (10000600, 10000627)            0.152607   \n",
      "143            (10000600, 10000628)            (10000627)            0.169950   \n",
      "142            (10000600, 10000627)            (10000628)            0.199286   \n",
      "147                      (10000628)  (10000600, 10000627)            0.216609   \n",
      "3                        (10000378)            (10000512)            0.128298   \n",
      "82             (10000600, 10000586)            (10000504)            0.134526   \n",
      "15                       (10000586)            (10000504)            0.181663   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \n",
      "179            0.209108  0.083354    0.850180  4.065739  0.062852    5.278954  \n",
      "178            0.152707  0.083354    0.613977  4.020611  0.062622    2.194926  \n",
      "183            0.135761  0.083354    0.545842  4.020611  0.062622    1.902948  \n",
      "184            0.152607  0.086368    0.604283  3.959723  0.064556    2.141410  \n",
      "189            0.142926  0.086368    0.565948  3.959723  0.064556    1.974588  \n",
      "180            0.196457  0.083354    0.769119  3.914955  0.062063    3.480338  \n",
      "202            0.142926  0.065882    0.559242  3.912806  0.049044    1.944547  \n",
      "196            0.152607  0.065882    0.595893  3.904745  0.049010    2.096951  \n",
      "185            0.216609  0.086368    0.838371  3.870427  0.064053    4.846839  \n",
      "197            0.216609  0.065882    0.836441  3.861516  0.048821    4.789643  \n",
      "204            0.169950  0.065882    0.639514  3.762956  0.048374    2.302584  \n",
      "52             0.152707  0.108376    0.518277  3.393921  0.076444    1.758878  \n",
      "53             0.209108  0.108376    0.709697  3.393921  0.076444    2.724371  \n",
      "198            0.252869  0.065882    0.849279  3.358576  0.046266    4.957045  \n",
      "107            0.196457  0.057667    0.657138  3.344949  0.040427    2.343633  \n",
      "186            0.252869  0.086368    0.845230  3.342564  0.060529    4.827365  \n",
      "49             0.196457  0.135761    0.649237  3.304734  0.094680    2.290845  \n",
      "48             0.209108  0.135761    0.691048  3.304734  0.094680    2.559915  \n",
      "130            0.209108  0.072622    0.688458  3.292349  0.050564    2.538634  \n",
      "139            0.209108  0.058880    0.687140  3.286045  0.040962    2.527937  \n",
      "138            0.152707  0.058880    0.501640  3.284980  0.040956    1.700164  \n",
      "51             0.196457  0.098043    0.642031  3.268053  0.068042    2.244728  \n",
      "106            0.209108  0.057667    0.680401  3.253819  0.039944    2.474636  \n",
      "205            0.199286  0.065882    0.644746  3.235281  0.045518    2.253919  \n",
      "131            0.196457  0.072622    0.618717  3.149382  0.049563    2.107473  \n",
      "135            0.196457  0.052176    0.608903  3.099427  0.035342    2.054589  \n",
      "61             0.216609  0.102183    0.669579  3.091181  0.069126    2.370885  \n",
      "161            0.216609  0.077574    0.658491  3.039992  0.052056    2.293908  \n",
      "165            0.169950  0.077574    0.508323  2.991019  0.051638    1.688203  \n",
      "190            0.216609  0.059957    0.606320  2.799139  0.038537    1.989916  \n",
      "57             0.252869  0.103019    0.675057  2.669594  0.064429    2.299269  \n",
      "149            0.252869  0.078765    0.668598  2.644050  0.048975    2.254454  \n",
      "55             0.252869  0.142926    0.659834  2.609392  0.088152    2.196370  \n",
      "54             0.216609  0.142926    0.565219  2.609392  0.088152    1.801804  \n",
      "191            0.252869  0.059957    0.656201  2.595025  0.036852    2.173162  \n",
      "153            0.199286  0.078765    0.516125  2.589874  0.048352    1.654796  \n",
      "143            0.252869  0.110560    0.650544  2.572656  0.067585    2.137985  \n",
      "142            0.216609  0.110560    0.554780  2.561201  0.067393    1.759560  \n",
      "147            0.199286  0.110560    0.510411  2.561201  0.067393    1.635483  \n",
      "3              0.273738  0.073253    0.570961  2.085794  0.038133    1.692765  \n",
      "82             0.368615  0.085268    0.633838  1.719514  0.035680    1.724334  \n",
      "15             0.368615  0.104699    0.576336  1.563518  0.037735    1.490297  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create frequent item sets\n",
    "# rules = minimum support 5%\n",
    "print(\"creating frequent itemsets with minimum support of 5%....\")\n",
    "frequent_itemsets  = apriori(basket_df, min_support=0.05, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# create association rules\n",
    "print(\"creating association rules [support, confidence, lift,  leverage, conviction] with minimum lift of 1 .......\")\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1).sort_values('lift', ascending=False)\n",
    "print(rules)\n",
    "\n",
    "# clean rules\n",
    "print(\"further cleaning of association rules [confidence >= 0.5, lift >= 1.5]....\")\n",
    "rules = rules[rules['confidence'] >= 0.5]\n",
    "rules = rules[rules['lift'] >= 1.5]\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting data....\n",
      "splitting antecedents and consequents into separate columns....\n",
      "                      antecedents         consequents  antecedent support  \\\n",
      "179            10000602, 10000604            10000603            0.098043   \n",
      "178            10000602, 10000603            10000604            0.135761   \n",
      "183                      10000604  10000602, 10000603            0.152707   \n",
      "184            10000627, 10000628            10000629            0.142926   \n",
      "189                      10000629  10000627, 10000628            0.152607   \n",
      "180            10000603, 10000604            10000602            0.108376   \n",
      "202            10000600, 10000629  10000627, 10000628            0.117806   \n",
      "196  10000600, 10000627, 10000628            10000629            0.110560   \n",
      "185            10000627, 10000629            10000628            0.103019   \n",
      "197  10000600, 10000627, 10000629            10000628            0.078765   \n",
      "204            10000627, 10000629  10000600, 10000628            0.103019   \n",
      "52                       10000603            10000604            0.209108   \n",
      "53                       10000604            10000603            0.152707   \n",
      "198  10000600, 10000628, 10000629            10000627            0.077574   \n",
      "107            10000512, 10000603            10000602            0.087755   \n",
      "186            10000628, 10000629            10000627            0.102183   \n",
      "49                       10000603            10000602            0.209108   \n",
      "48                       10000602            10000603            0.196457   \n",
      "130            10000600, 10000602            10000603            0.105485   \n",
      "139            10000600, 10000604            10000603            0.085688   \n",
      "138            10000600, 10000603            10000604            0.117375   \n",
      "51                       10000604            10000602            0.152707   \n",
      "106            10000512, 10000602            10000603            0.084755   \n",
      "205            10000628, 10000629  10000600, 10000627            0.102183   \n",
      "131            10000600, 10000603            10000602            0.117375   \n",
      "135            10000600, 10000604            10000602            0.085688   \n",
      "61                       10000629            10000628            0.152607   \n",
      "161            10000600, 10000629            10000628            0.117806   \n",
      "165                      10000629  10000600, 10000628            0.152607   \n",
      "190            10000640, 10000627            10000628            0.098886   \n",
      "57                       10000629            10000627            0.152607   \n",
      "149            10000600, 10000629            10000627            0.117806   \n",
      "55                       10000628            10000627            0.216609   \n",
      "54                       10000627            10000628            0.252869   \n",
      "191            10000640, 10000628            10000627            0.091369   \n",
      "153                      10000629  10000600, 10000627            0.152607   \n",
      "143            10000600, 10000628            10000627            0.169950   \n",
      "142            10000600, 10000627            10000628            0.199286   \n",
      "147                      10000628  10000600, 10000627            0.216609   \n",
      "3                        10000378            10000512            0.128298   \n",
      "82             10000600, 10000586            10000504            0.134526   \n",
      "15                       10000586            10000504            0.181663   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "179            0.209108  0.083354    0.850180  4.065739  0.062852    5.278954   \n",
      "178            0.152707  0.083354    0.613977  4.020611  0.062622    2.194926   \n",
      "183            0.135761  0.083354    0.545842  4.020611  0.062622    1.902948   \n",
      "184            0.152607  0.086368    0.604283  3.959723  0.064556    2.141410   \n",
      "189            0.142926  0.086368    0.565948  3.959723  0.064556    1.974588   \n",
      "180            0.196457  0.083354    0.769119  3.914955  0.062063    3.480338   \n",
      "202            0.142926  0.065882    0.559242  3.912806  0.049044    1.944547   \n",
      "196            0.152607  0.065882    0.595893  3.904745  0.049010    2.096951   \n",
      "185            0.216609  0.086368    0.838371  3.870427  0.064053    4.846839   \n",
      "197            0.216609  0.065882    0.836441  3.861516  0.048821    4.789643   \n",
      "204            0.169950  0.065882    0.639514  3.762956  0.048374    2.302584   \n",
      "52             0.152707  0.108376    0.518277  3.393921  0.076444    1.758878   \n",
      "53             0.209108  0.108376    0.709697  3.393921  0.076444    2.724371   \n",
      "198            0.252869  0.065882    0.849279  3.358576  0.046266    4.957045   \n",
      "107            0.196457  0.057667    0.657138  3.344949  0.040427    2.343633   \n",
      "186            0.252869  0.086368    0.845230  3.342564  0.060529    4.827365   \n",
      "49             0.196457  0.135761    0.649237  3.304734  0.094680    2.290845   \n",
      "48             0.209108  0.135761    0.691048  3.304734  0.094680    2.559915   \n",
      "130            0.209108  0.072622    0.688458  3.292349  0.050564    2.538634   \n",
      "139            0.209108  0.058880    0.687140  3.286045  0.040962    2.527937   \n",
      "138            0.152707  0.058880    0.501640  3.284980  0.040956    1.700164   \n",
      "51             0.196457  0.098043    0.642031  3.268053  0.068042    2.244728   \n",
      "106            0.209108  0.057667    0.680401  3.253819  0.039944    2.474636   \n",
      "205            0.199286  0.065882    0.644746  3.235281  0.045518    2.253919   \n",
      "131            0.196457  0.072622    0.618717  3.149382  0.049563    2.107473   \n",
      "135            0.196457  0.052176    0.608903  3.099427  0.035342    2.054589   \n",
      "61             0.216609  0.102183    0.669579  3.091181  0.069126    2.370885   \n",
      "161            0.216609  0.077574    0.658491  3.039992  0.052056    2.293908   \n",
      "165            0.169950  0.077574    0.508323  2.991019  0.051638    1.688203   \n",
      "190            0.216609  0.059957    0.606320  2.799139  0.038537    1.989916   \n",
      "57             0.252869  0.103019    0.675057  2.669594  0.064429    2.299269   \n",
      "149            0.252869  0.078765    0.668598  2.644050  0.048975    2.254454   \n",
      "55             0.252869  0.142926    0.659834  2.609392  0.088152    2.196370   \n",
      "54             0.216609  0.142926    0.565219  2.609392  0.088152    1.801804   \n",
      "191            0.252869  0.059957    0.656201  2.595025  0.036852    2.173162   \n",
      "153            0.199286  0.078765    0.516125  2.589874  0.048352    1.654796   \n",
      "143            0.252869  0.110560    0.650544  2.572656  0.067585    2.137985   \n",
      "142            0.216609  0.110560    0.554780  2.561201  0.067393    1.759560   \n",
      "147            0.199286  0.110560    0.510411  2.561201  0.067393    1.635483   \n",
      "3              0.273738  0.073253    0.570961  2.085794  0.038133    1.692765   \n",
      "82             0.368615  0.085268    0.633838  1.719514  0.035680    1.724334   \n",
      "15             0.368615  0.104699    0.576336  1.563518  0.037735    1.490297   \n",
      "\n",
      "    antecedent_0 antecedent_1 antecedent_2 consequent_0 consequent_1  \n",
      "179     10000602     10000604         None     10000603         None  \n",
      "178     10000602     10000603         None     10000604         None  \n",
      "183     10000604         None         None     10000602     10000603  \n",
      "184     10000627     10000628         None     10000629         None  \n",
      "189     10000629         None         None     10000627     10000628  \n",
      "180     10000603     10000604         None     10000602         None  \n",
      "202     10000600     10000629         None     10000627     10000628  \n",
      "196     10000600     10000627     10000628     10000629         None  \n",
      "185     10000627     10000629         None     10000628         None  \n",
      "197     10000600     10000627     10000629     10000628         None  \n",
      "204     10000627     10000629         None     10000600     10000628  \n",
      "52      10000603         None         None     10000604         None  \n",
      "53      10000604         None         None     10000603         None  \n",
      "198     10000600     10000628     10000629     10000627         None  \n",
      "107     10000512     10000603         None     10000602         None  \n",
      "186     10000628     10000629         None     10000627         None  \n",
      "49      10000603         None         None     10000602         None  \n",
      "48      10000602         None         None     10000603         None  \n",
      "130     10000600     10000602         None     10000603         None  \n",
      "139     10000600     10000604         None     10000603         None  \n",
      "138     10000600     10000603         None     10000604         None  \n",
      "51      10000604         None         None     10000602         None  \n",
      "106     10000512     10000602         None     10000603         None  \n",
      "205     10000628     10000629         None     10000600     10000627  \n",
      "131     10000600     10000603         None     10000602         None  \n",
      "135     10000600     10000604         None     10000602         None  \n",
      "61      10000629         None         None     10000628         None  \n",
      "161     10000600     10000629         None     10000628         None  \n",
      "165     10000629         None         None     10000600     10000628  \n",
      "190     10000640     10000627         None     10000628         None  \n",
      "57      10000629         None         None     10000627         None  \n",
      "149     10000600     10000629         None     10000627         None  \n",
      "55      10000628         None         None     10000627         None  \n",
      "54      10000627         None         None     10000628         None  \n",
      "191     10000640     10000628         None     10000627         None  \n",
      "153     10000629         None         None     10000600     10000627  \n",
      "143     10000600     10000628         None     10000627         None  \n",
      "142     10000600     10000627         None     10000628         None  \n",
      "147     10000628         None         None     10000600     10000627  \n",
      "3       10000378         None         None     10000512         None  \n",
      "82      10000600     10000586         None     10000504         None  \n",
      "15      10000586         None         None     10000504         None  \n"
     ]
    }
   ],
   "source": [
    "#  Preparing clean data for Tableau (from frozenset to string) \n",
    "print(\"formatting data....\")\n",
    "rules[\"antecedents\"] = rules[\"antecedents\"].apply(lambda x: ', '.join([str(i) for i in list(x)])).astype(\"unicode\")\n",
    "rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: ', '.join([str(i) for i in list(x)])).astype(\"unicode\")\n",
    "\n",
    "# split antecedents and consequents into separate columns\n",
    "print(\"splitting antecedents and consequents into separate columns....\")\n",
    "rules = rules.join(rules['antecedents'].str.split(',', expand=True).add_prefix('antecedent_'))\n",
    "rules = rules.join(rules['consequents'].str.split(',', expand=True).add_prefix('consequent_'))\n",
    "\n",
    "# # Explode the consequents column to get the consequents in separate rows\n",
    "# print(\"Exploding consequents column....\")\n",
    "# rules = rules.assign(**{'consequents': rules['consequents'].str.split(',')}).explode('consequents')\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping rules to relevant information....\n"
     ]
    }
   ],
   "source": [
    "# mapping rules to relevant information.... \n",
    "print(\"mapping rules to relevant information....\")\n",
    "code_to_name_dict = pd.Series(df[\"ProductNameTH\"].values, index=df[\"ProductCode\"]).to_dict()\n",
    "code_to_group_level1_dict = pd.Series(df[\"GroupNameLevel1\"].values, index=df[\"ProductCode\"]).to_dict()\n",
    "code_to_group_level2_dict = pd.Series(df[\"GroupNameLevel2\"].values, index=df[\"ProductCode\"]).to_dict()\n",
    "code_to_name_dict = {str(key): str(value) for key, value in code_to_name_dict.items()}\n",
    "code_to_group_level1_dict = {str(key): str(value) for key, value in code_to_group_level1_dict.items()}\n",
    "code_to_group_level2_dict = {str(key): str(value) for key, value in code_to_group_level2_dict.items()}\n",
    "total_revenue_pdt_code_dict = df.groupby(['ProductCode'])['NetAmount'].sum().to_dict()\n",
    "total_revenue_pdt_code_dict = {str(key): str(round(value, 2)) for key, value in total_revenue_pdt_code_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing antecedent columns....\n",
      "Index(['antecedents', 'consequents', 'antecedent support',\n",
      "       'consequent support', 'support', 'confidence', 'lift', 'leverage',\n",
      "       'conviction'],\n",
      "      dtype='object')\n",
      "antecedents\n",
      "consequents\n",
      "antecedent support\n",
      "consequent support\n",
      "support\n",
      "confidence\n",
      "lift\n",
      "leverage\n",
      "                        antecedents           consequents  antecedent support  \\\n",
      "179            (10000602, 10000604)            (10000603)            0.098043   \n",
      "178            (10000602, 10000603)            (10000604)            0.135761   \n",
      "183                      (10000604)  (10000602, 10000603)            0.152707   \n",
      "184            (10000627, 10000628)            (10000629)            0.142926   \n",
      "189                      (10000629)  (10000627, 10000628)            0.152607   \n",
      "180            (10000603, 10000604)            (10000602)            0.108376   \n",
      "202            (10000600, 10000629)  (10000627, 10000628)            0.117806   \n",
      "196  (10000600, 10000627, 10000628)            (10000629)            0.110560   \n",
      "185            (10000627, 10000629)            (10000628)            0.103019   \n",
      "197  (10000600, 10000627, 10000629)            (10000628)            0.078765   \n",
      "204            (10000627, 10000629)  (10000600, 10000628)            0.103019   \n",
      "52                       (10000603)            (10000604)            0.209108   \n",
      "53                       (10000604)            (10000603)            0.152707   \n",
      "198  (10000600, 10000628, 10000629)            (10000627)            0.077574   \n",
      "107            (10000512, 10000603)            (10000602)            0.087755   \n",
      "186            (10000628, 10000629)            (10000627)            0.102183   \n",
      "49                       (10000603)            (10000602)            0.209108   \n",
      "48                       (10000602)            (10000603)            0.196457   \n",
      "130            (10000600, 10000602)            (10000603)            0.105485   \n",
      "139            (10000600, 10000604)            (10000603)            0.085688   \n",
      "138            (10000600, 10000603)            (10000604)            0.117375   \n",
      "51                       (10000604)            (10000602)            0.152707   \n",
      "106            (10000512, 10000602)            (10000603)            0.084755   \n",
      "205            (10000628, 10000629)  (10000600, 10000627)            0.102183   \n",
      "131            (10000600, 10000603)            (10000602)            0.117375   \n",
      "135            (10000600, 10000604)            (10000602)            0.085688   \n",
      "61                       (10000629)            (10000628)            0.152607   \n",
      "161            (10000600, 10000629)            (10000628)            0.117806   \n",
      "165                      (10000629)  (10000600, 10000628)            0.152607   \n",
      "190            (10000640, 10000627)            (10000628)            0.098886   \n",
      "57                       (10000629)            (10000627)            0.152607   \n",
      "149            (10000600, 10000629)            (10000627)            0.117806   \n",
      "55                       (10000628)            (10000627)            0.216609   \n",
      "54                       (10000627)            (10000628)            0.252869   \n",
      "191            (10000640, 10000628)            (10000627)            0.091369   \n",
      "153                      (10000629)  (10000600, 10000627)            0.152607   \n",
      "143            (10000600, 10000628)            (10000627)            0.169950   \n",
      "142            (10000600, 10000627)            (10000628)            0.199286   \n",
      "147                      (10000628)  (10000600, 10000627)            0.216609   \n",
      "3                        (10000378)            (10000512)            0.128298   \n",
      "82             (10000600, 10000586)            (10000504)            0.134526   \n",
      "15                       (10000586)            (10000504)            0.181663   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \n",
      "179            0.209108  0.083354    0.850180  4.065739  0.062852    5.278954  \n",
      "178            0.152707  0.083354    0.613977  4.020611  0.062622    2.194926  \n",
      "183            0.135761  0.083354    0.545842  4.020611  0.062622    1.902948  \n",
      "184            0.152607  0.086368    0.604283  3.959723  0.064556    2.141410  \n",
      "189            0.142926  0.086368    0.565948  3.959723  0.064556    1.974588  \n",
      "180            0.196457  0.083354    0.769119  3.914955  0.062063    3.480338  \n",
      "202            0.142926  0.065882    0.559242  3.912806  0.049044    1.944547  \n",
      "196            0.152607  0.065882    0.595893  3.904745  0.049010    2.096951  \n",
      "185            0.216609  0.086368    0.838371  3.870427  0.064053    4.846839  \n",
      "197            0.216609  0.065882    0.836441  3.861516  0.048821    4.789643  \n",
      "204            0.169950  0.065882    0.639514  3.762956  0.048374    2.302584  \n",
      "52             0.152707  0.108376    0.518277  3.393921  0.076444    1.758878  \n",
      "53             0.209108  0.108376    0.709697  3.393921  0.076444    2.724371  \n",
      "198            0.252869  0.065882    0.849279  3.358576  0.046266    4.957045  \n",
      "107            0.196457  0.057667    0.657138  3.344949  0.040427    2.343633  \n",
      "186            0.252869  0.086368    0.845230  3.342564  0.060529    4.827365  \n",
      "49             0.196457  0.135761    0.649237  3.304734  0.094680    2.290845  \n",
      "48             0.209108  0.135761    0.691048  3.304734  0.094680    2.559915  \n",
      "130            0.209108  0.072622    0.688458  3.292349  0.050564    2.538634  \n",
      "139            0.209108  0.058880    0.687140  3.286045  0.040962    2.527937  \n",
      "138            0.152707  0.058880    0.501640  3.284980  0.040956    1.700164  \n",
      "51             0.196457  0.098043    0.642031  3.268053  0.068042    2.244728  \n",
      "106            0.209108  0.057667    0.680401  3.253819  0.039944    2.474636  \n",
      "205            0.199286  0.065882    0.644746  3.235281  0.045518    2.253919  \n",
      "131            0.196457  0.072622    0.618717  3.149382  0.049563    2.107473  \n",
      "135            0.196457  0.052176    0.608903  3.099427  0.035342    2.054589  \n",
      "61             0.216609  0.102183    0.669579  3.091181  0.069126    2.370885  \n",
      "161            0.216609  0.077574    0.658491  3.039992  0.052056    2.293908  \n",
      "165            0.169950  0.077574    0.508323  2.991019  0.051638    1.688203  \n",
      "190            0.216609  0.059957    0.606320  2.799139  0.038537    1.989916  \n",
      "57             0.252869  0.103019    0.675057  2.669594  0.064429    2.299269  \n",
      "149            0.252869  0.078765    0.668598  2.644050  0.048975    2.254454  \n",
      "55             0.252869  0.142926    0.659834  2.609392  0.088152    2.196370  \n",
      "54             0.216609  0.142926    0.565219  2.609392  0.088152    1.801804  \n",
      "191            0.252869  0.059957    0.656201  2.595025  0.036852    2.173162  \n",
      "153            0.199286  0.078765    0.516125  2.589874  0.048352    1.654796  \n",
      "143            0.252869  0.110560    0.650544  2.572656  0.067585    2.137985  \n",
      "142            0.216609  0.110560    0.554780  2.561201  0.067393    1.759560  \n",
      "147            0.199286  0.110560    0.510411  2.561201  0.067393    1.635483  \n",
      "3              0.273738  0.073253    0.570961  2.085794  0.038133    1.692765  \n",
      "82             0.368615  0.085268    0.633838  1.719514  0.035680    1.724334  \n",
      "15             0.368615  0.104699    0.576336  1.563518  0.037735    1.490297  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def updateRules(rules, dictUsed, colNameOut, colIndex, ant_con):\n",
    "    for row in rules.itertuples():\n",
    "        # basket = []\n",
    "        print(str(row[i+1]).strip())\n",
    "        if (ant_con == 1 and row[i+1] != None):\n",
    "            # for pdt in list(row.antecedents.split(',')):\n",
    "            pdt_name = dictUsed[str(row[i+1]).strip()]\n",
    "            # basket.append(pdt_name)\n",
    "            # rules.at[row.Index, colNameOut] = ', '.join(basket)\n",
    "            rules.at[row.Index, colNameOut] = pdt_name\n",
    "        elif (ant_con == 0 and row[i+1] != None):\n",
    "            pdt_name = dictUsed[str(row[i+1]).strip()]\n",
    "            print(pdt_name)\n",
    "            rules.at[row.Index, colNameOut] = pdt_name\n",
    "\n",
    "    return rules\n",
    "\n",
    "# find and process antecedent columns\n",
    "print(\"processing antecedent columns....\")\n",
    "print(rules.columns)\n",
    "for i in range(len(rules.columns)-1):\n",
    "    print(rules.columns[i])\n",
    "    if \"antecedent_\" in rules.columns[i]:\n",
    "        rules = updateRules(rules, code_to_name_dict, i, \"ant_thai\", 1)\n",
    "        rules = updateRules(rules, code_to_group_level1_dict, \"ant_grouplevel1\", i, 1)\n",
    "        rules = updateRules(rules, code_to_group_level2_dict, i, \"ant_grouplevel2\", 1)\n",
    "        rules = updateRules(rules, total_revenue_pdt_code_dict, i, \"ant_pdt_ttl_net_amt\", 1)\n",
    "    \n",
    "    if \"consequents_\" in rules.columns[i]:\n",
    "        rules = updateRules(rules, code_to_name_dict, i, \"con_thai\", 0)\n",
    "        rules = updateRules(rules, code_to_group_level1_dict, i, \"con_grouplevel1\", 0)\n",
    "        rules = updateRules(rules, code_to_group_level2_dict, i, \"con_grouplevel2\", 0)\n",
    "        rules = updateRules(rules, total_revenue_pdt_code_dict, i, \"con_pdt_ttl_net_amt\", 0)\n",
    "\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting association rules to CSV....\n"
     ]
    }
   ],
   "source": [
    "# export rules to csv\n",
    "print(\"exporting association rules to CSV....\")\n",
    "rules.to_csv(\"../ETL/CSV/association_rules.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a77d96197af7bc4b552fad6e75279d6baa537d378ffe8d97983a2225799e48a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
